{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2U10WROcZUj",
        "outputId": "5efb4807-8152-455c-f7c4-01a6dd2d7677"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0-train Loss: 0.3502 Acc: 0.8712\n",
            "0-val Loss: 0.0446 Acc: 1.0000\n",
            "1-train Loss: 0.0709 Acc: 0.9807\n",
            "1-val Loss: 0.0472 Acc: 0.9808\n",
            "2-train Loss: 0.0450 Acc: 0.9871\n",
            "2-val Loss: 0.1159 Acc: 0.9679\n",
            "3-train Loss: 0.0352 Acc: 0.9903\n",
            "3-val Loss: 0.0695 Acc: 0.9744\n",
            "4-train Loss: 0.0418 Acc: 0.9887\n",
            "4-val Loss: 0.0383 Acc: 0.9744\n",
            "5-train Loss: 0.0301 Acc: 0.9903\n",
            "5-val Loss: 0.0679 Acc: 0.9808\n",
            "6-train Loss: 0.0171 Acc: 0.9952\n",
            "6-val Loss: 0.0530 Acc: 0.9872\n",
            "7-train Loss: 0.0078 Acc: 0.9984\n",
            "7-val Loss: 0.0554 Acc: 0.9744\n",
            "8-train Loss: 0.0097 Acc: 0.9968\n",
            "8-val Loss: 0.0547 Acc: 0.9808\n",
            "9-train Loss: 0.0163 Acc: 0.9936\n",
            "9-val Loss: 0.0398 Acc: 0.9744\n",
            "10-train Loss: 0.0482 Acc: 0.9855\n",
            "10-val Loss: 0.0668 Acc: 0.9808\n",
            "11-train Loss: 0.0091 Acc: 0.9968\n",
            "11-val Loss: 0.0679 Acc: 0.9615\n",
            "12-train Loss: 0.0047 Acc: 0.9984\n",
            "12-val Loss: 0.0801 Acc: 0.9744\n",
            "13-train Loss: 0.0160 Acc: 0.9936\n",
            "13-val Loss: 0.0341 Acc: 0.9872\n",
            "14-train Loss: 0.0080 Acc: 0.9968\n",
            "14-val Loss: 0.1172 Acc: 0.9744\n",
            "15-train Loss: 0.0167 Acc: 0.9919\n",
            "15-val Loss: 0.0646 Acc: 0.9744\n",
            "16-train Loss: 0.0088 Acc: 0.9984\n",
            "16-val Loss: 0.1108 Acc: 0.9808\n",
            "17-train Loss: 0.0231 Acc: 0.9936\n",
            "17-val Loss: 0.0519 Acc: 0.9808\n",
            "18-train Loss: 0.0072 Acc: 0.9984\n",
            "18-val Loss: 0.0623 Acc: 0.9872\n",
            "19-train Loss: 0.0021 Acc: 1.0000\n",
            "19-val Loss: 0.0529 Acc: 0.9808\n",
            "20-train Loss: 0.0020 Acc: 1.0000\n",
            "20-val Loss: 0.0607 Acc: 0.9872\n",
            "21-train Loss: 0.0011 Acc: 1.0000\n",
            "21-val Loss: 0.0663 Acc: 0.9808\n",
            "22-train Loss: 0.0004 Acc: 1.0000\n",
            "22-val Loss: 0.0673 Acc: 0.9808\n",
            "23-train Loss: 0.0010 Acc: 1.0000\n",
            "23-val Loss: 0.1091 Acc: 0.9808\n",
            "24-train Loss: 0.0003 Acc: 1.0000\n",
            "24-val Loss: 0.1005 Acc: 0.9808\n",
            "Jenis Prediction Distribution: {0: 206, 1: 128}\n"
          ]
        },
        {
          "ename": "PermissionError",
          "evalue": "[Errno 13] Permission denied: 'submission.xlsx'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 213\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;66;03m# Save to Excel\u001b[39;00m\n\u001b[0;32m    212\u001b[0m submission_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(predictions)\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 213\u001b[0m \u001b[43msubmission_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msubmission.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredictions saved to submission.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\venv\\lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\venv\\lib\\site-packages\\pandas\\core\\generic.py:2417\u001b[0m, in \u001b[0;36mNDFrame.to_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, inf_rep, freeze_panes, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   2404\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExcelFormatter\n\u001b[0;32m   2406\u001b[0m formatter \u001b[38;5;241m=\u001b[39m ExcelFormatter(\n\u001b[0;32m   2407\u001b[0m     df,\n\u001b[0;32m   2408\u001b[0m     na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2415\u001b[0m     inf_rep\u001b[38;5;241m=\u001b[39minf_rep,\n\u001b[0;32m   2416\u001b[0m )\n\u001b[1;32m-> 2417\u001b[0m \u001b[43mformatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2418\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexcel_writer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2419\u001b[0m \u001b[43m    \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartcol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartcol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreeze_panes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreeze_panes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2426\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\venv\\lib\\site-packages\\pandas\\io\\formats\\excel.py:943\u001b[0m, in \u001b[0;36mExcelFormatter.write\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m    941\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    942\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 943\u001b[0m     writer \u001b[38;5;241m=\u001b[39m \u001b[43mExcelWriter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    949\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\venv\\lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:61\u001b[0m, in \u001b[0;36mOpenpyxlWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenpyxl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mworkbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Workbook\n\u001b[0;32m     59\u001b[0m engine_kwargs \u001b[38;5;241m=\u001b[39m combine_kwargs(engine_kwargs, kwargs)\n\u001b[1;32m---> 61\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_sheet_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_sheet_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# ExcelWriter replaced \"a\" by \"r+\" to allow us to first read the excel file from\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# the file and later write to it\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode:  \u001b[38;5;66;03m# Load from existing workbook\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\venv\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1246\u001b[0m, in \u001b[0;36mExcelWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs)\u001b[0m\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles \u001b[38;5;241m=\u001b[39m IOHandles(\n\u001b[0;32m   1243\u001b[0m     cast(IO[\u001b[38;5;28mbytes\u001b[39m], path), compression\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m   1244\u001b[0m )\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, ExcelWriter):\n\u001b[1;32m-> 1246\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1248\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1249\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cur_sheet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m date_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\venv\\lib\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
            "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'submission.xlsx'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "from torchvision.models import ResNet50_Weights\n",
        "import numpy as np\n",
        "from torch.optim.swa_utils import AveragedModel, SWALR\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load the train.csv file\n",
        "df = pd.read_csv('train.csv')\n",
        "\n",
        "# Define paths\n",
        "train_img_path = 'train/train'\n",
        "output_path = 'prepared_data'\n",
        "\n",
        "# Split dataset into train and validation sets (80% train, 20% val)\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Mapping for jenis to human-readable labels\n",
        "jenis_dict = {0: 'kaos', 1: 'hoodie'}\n",
        "\n",
        "class MultilabelDataset(Dataset):\n",
        "    def __init__(self, dataframe, img_dir, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.dataframe.iloc[idx]['id']\n",
        "        img_path_jpg = os.path.join(self.img_dir, f'{img_id}.jpg')\n",
        "        img_path_png = os.path.join(self.img_dir, f'{img_id}.png')\n",
        "        \n",
        "        if os.path.exists(img_path_jpg):\n",
        "            img_path = img_path_jpg\n",
        "        elif os.path.exists(img_path_png):\n",
        "            img_path = img_path_png\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        jenis_label = self.dataframe.iloc[idx]['jenis']\n",
        "        label = torch.tensor(jenis_label)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Define transformations\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# Dataset and DataLoader setup\n",
        "train_dataset = MultilabelDataset(train_df, train_img_path, transform=data_transforms['train'])\n",
        "val_dataset = MultilabelDataset(val_df, train_img_path, transform=data_transforms['val'])\n",
        "\n",
        "# Custom collate function\n",
        "def collate_fn(batch):\n",
        "    batch = list(filter(lambda x: x is not None, batch))\n",
        "    return torch.utils.data.dataloader.default_collate(batch)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0, pin_memory=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0, pin_memory=True, collate_fn=collate_fn)\n",
        "\n",
        "dataloaders = {'train': train_loader, 'val': val_loader}\n",
        "dataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset)}\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Model Definition with MC Dropout\n",
        "class CustomResNetWithMC(nn.Module):\n",
        "    def __init__(self, num_classes_type=2):\n",
        "        super(CustomResNetWithMC, self).__init__()\n",
        "        self.model = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
        "        num_ftrs = self.model.fc.in_features\n",
        "        self.model.fc = nn.Sequential(\n",
        "            nn.Linear(num_ftrs, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),  # MC Dropout\n",
        "            nn.Linear(256, num_classes_type)  # 2 for jenis (kaos and hoodie)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Initialize model, criteria, optimizer, and scheduler\n",
        "model = CustomResNetWithMC().to(device)\n",
        "swa_model = AveragedModel(model).to(device)\n",
        "\n",
        "# Optimizer and SWA scheduler\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "scheduler = SWALR(optimizer, anneal_strategy='cos', anneal_epochs=5, swa_lr=0.0001)\n",
        "\n",
        "# Class weights for loss\n",
        "jenis_counts = train_df['jenis'].value_counts().sort_index().values\n",
        "class_weights_jenis = 1. / torch.tensor(jenis_counts, dtype=torch.float).to(device)\n",
        "criterion_jenis = nn.CrossEntropyLoss(weight=class_weights_jenis)\n",
        "\n",
        "# Training function\n",
        "def train_model(model, swa_model, optimizer, scheduler, num_epochs=25):\n",
        "    best_model_wts = model.state_dict()\n",
        "    for epoch in range(num_epochs):\n",
        "        for phase in ['train', 'val']:\n",
        "            model.train() if phase == 'train' else model.eval()\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion_jenis(outputs, labels)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    running_loss += loss.item() * inputs.size(0)\n",
        "                    running_corrects += (preds == labels).sum().item()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
        "\n",
        "            print(f'{epoch}-{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "            if phase == 'train':\n",
        "                swa_model.update_parameters(model)\n",
        "                scheduler.step()\n",
        "\n",
        "        if epoch >= (num_epochs - 5):\n",
        "            torch.optim.swa_utils.update_bn(dataloaders['train'], swa_model, device=device)\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return swa_model\n",
        "\n",
        "# Training with SWA\n",
        "model = train_model(model, swa_model, optimizer, scheduler, num_epochs=25)\n",
        "\n",
        "# Testing function with MC Dropout for Bayesian inference\n",
        "def bayesian_predict_mc_dropout(model, image, n_samples=50):\n",
        "    model.eval()\n",
        "    preds_jenis = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(n_samples):\n",
        "            output = model(image)\n",
        "            output_jenis = output[:, :2]\n",
        "            preds_jenis.append(torch.softmax(output_jenis, dim=1).cpu().numpy())\n",
        "\n",
        "    mean_jenis = np.mean(preds_jenis, axis=0)\n",
        "    uncertainty_jenis = np.std(preds_jenis, axis=0)\n",
        "\n",
        "    return mean_jenis, uncertainty_jenis\n",
        "\n",
        "# Directory containing test images\n",
        "test_dir = 'test/test'\n",
        "supported_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.gif')\n",
        "test_images = [f for f in os.listdir(test_dir) if f.lower().endswith(supported_extensions)]\n",
        "\n",
        "predictions = []\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Count predictions for each label for debugging purposes\n",
        "jenis_counts = {}\n",
        "\n",
        "for image_name in test_images:\n",
        "    image_path = os.path.join(test_dir, image_name)\n",
        "    img = Image.open(image_path).convert('RGB')\n",
        "    img = transform(img).unsqueeze(0).to(device)\n",
        "    mean_jenis, _ = bayesian_predict_mc_dropout(model, img)\n",
        "\n",
        "    jenis_pred = np.argmax(mean_jenis, axis=1).item()\n",
        "\n",
        "    # Add predictions to list\n",
        "    predictions.append({'id': int(os.path.splitext(image_name)[0]), 'jenis': jenis_pred})\n",
        "\n",
        "    # Update counts for debug\n",
        "    jenis_counts[jenis_pred] = jenis_counts.get(jenis_pred, 0) + 1\n",
        "\n",
        "# Print prediction distribution\n",
        "print(\"Jenis Prediction Distribution:\", jenis_counts)\n",
        "\n",
        "# Save to Excel\n",
        "submission_df = pd.DataFrame(predictions).sort_values(by='id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions saved to submission.xlsx\n"
          ]
        }
      ],
      "source": [
        "submission_df.to_excel('submission.xlsx', index=False)\n",
        "print(\"Predictions saved to submission.xlsx\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "databundleVersionId": 9761785,
          "sourceId": 86189,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30786,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
