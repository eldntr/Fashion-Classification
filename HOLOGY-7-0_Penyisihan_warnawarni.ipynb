{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":86189,"databundleVersionId":9761785,"sourceType":"competition"},{"sourceId":9721357,"sourceType":"datasetVersion","datasetId":5947820},{"sourceId":9721401,"sourceType":"datasetVersion","datasetId":5947853}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport os\nimport torch\nfrom torch.utils.data import Dataset\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nimport numpy as np\nfrom PIL import Image, ImageOps\n\n# Custom Dataset class\nclass CustomDataset(Dataset):\n    def __init__(self, csv_file, image_dir, transform=None):\n        self.labels_df = pd.read_csv(csv_file)\n        self.image_dir = image_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.labels_df)\n\n    def __getitem__(self, idx):\n        img_name = str(self.labels_df.iloc[idx, 0])\n        try:\n            img_path = os.path.join(self.image_dir, img_name + '.jpg')  \n            image = Image.open(img_path).convert(\"RGB\")\n        except:\n            img_path = os.path.join(self.image_dir, img_name + '.png')  \n            image = Image.open(img_path).convert(\"RGB\")\n        \n        label = int(self.labels_df.iloc[idx, 2])  # warna kolom index 2, jenis kolom index 1\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label\n\ncsv_file = '/kaggle/input/penyisihan-hology-7-data-mining-competition/train.csv'\ntrain_dir = '/kaggle/input/segmented-plis/train_segmented'\n\ntransform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  \n])\n\n# Create the dataset\ntrain_dataset = CustomDataset(csv_file=csv_file, image_dir=train_dir, transform=transform)\n\n# DataLoader for batching\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T13:01:42.025173Z","iopub.execute_input":"2024-10-27T13:01:42.025561Z","iopub.status.idle":"2024-10-27T13:01:47.563473Z","shell.execute_reply.started":"2024-10-27T13:01:42.025522Z","shell.execute_reply":"2024-10-27T13:01:47.562686Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass ImageCNN(nn.Module):\n    def __init__(self, num_classes=5):  \n        super(ImageCNN, self).__init__()\n        \n        # Convolutional layers with ReLU activations\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n        \n        # Pooling layer\n        self.pool = nn.MaxPool2d(2, 2)\n        \n        # Fully connected layers\n        self.fc1 = nn.Linear(128 * 32 * 32, 512)  # Adjusted input size based on 256x256 image\n        self.fc2 = nn.Linear(512, num_classes)  # Output layer for the number of classes\n\n    def forward(self, x):\n        # First conv layer + ReLU + pooling\n        x = self.pool(F.relu(self.conv1(x)))        \n        x = self.pool(F.relu(self.conv2(x)))\n        x = self.pool(F.relu(self.conv3(x)))\n        \n        x = torch.flatten(x, start_dim=1)  \n        \n        # Fully connected layers\n        x = F.relu(self.fc1(x))\n        \n        # Output layer (logits)\n        x = self.fc2(x)\n        \n        return x\n\n# Example usage:\nnum_classes = 5  # Set the correct number of classes for your dataset\nmodel = ImageCNN(num_classes=num_classes)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T13:09:16.139950Z","iopub.execute_input":"2024-10-27T13:09:16.140633Z","iopub.status.idle":"2024-10-27T13:09:16.690687Z","shell.execute_reply.started":"2024-10-27T13:09:16.140594Z","shell.execute_reply":"2024-10-27T13:09:16.689906Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-3)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T13:09:17.477984Z","iopub.execute_input":"2024-10-27T13:09:17.478824Z","iopub.status.idle":"2024-10-27T13:09:17.483182Z","shell.execute_reply.started":"2024-10-27T13:09:17.478784Z","shell.execute_reply":"2024-10-27T13:09:17.482204Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import torch.nn.functional as F\n\ndef train_model(model, train_loader, criterion, optimizer, num_epochs=50):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = model.to(device)  \n    \n    best_accuracy = 0.0\n    lowest_loss = float('inf')\n    best_model_state = None\n\n    for epoch in range(num_epochs):\n        model.train()  # Set model to training mode\n        running_loss = 0.0\n        correct = 0\n        total = 0\n\n\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)  # Move data to device\n\n            # Zero the parameter gradients\n            optimizer.zero_grad()\n\n            # Forward pass\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n\n            # Backward pass and optimization\n            loss.backward()\n            optimizer.step()\n\n            # Accumulate the loss\n            running_loss += loss.item()\n\n            # Compute predictions and accuracy\n            _, predicted = torch.max(outputs.data, 1)  # Get the class with highest score\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n        # Calculate accuracy\n        accuracy = 100 * correct / total\n        epoch_loss = running_loss / len(train_loader)\n        epoch_acc = (correct / total) * 100\n        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.6f}, Accuracy: {accuracy:.2f}%\")\n\n        # Check if this is the best model\n        if epoch_acc > best_accuracy or epoch_loss < lowest_loss:\n            best_accuracy = epoch_acc\n            lowest_loss = epoch_loss\n            best_model_state = model.state_dict()  # Save the model's state\n\n    # Save the best model after training\n    if best_model_state is not None:\n        torch.save(best_model_state, 'best_model.pth')\n        print(f\"Best Model Saved with Accuracy: {best_accuracy:.2f}%, Loss: {lowest_loss:.4f}\")\n\ntrain_model(model, train_loader, criterion, optimizer)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T13:09:18.112185Z","iopub.execute_input":"2024-10-27T13:09:18.112582Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch [1/50], Loss: 1.080767, Accuracy: 85.46%\nEpoch [2/50], Loss: 0.170478, Accuracy: 94.85%\nEpoch [3/50], Loss: 0.063063, Accuracy: 97.94%\nEpoch [4/50], Loss: 0.058433, Accuracy: 98.46%\nEpoch [5/50], Loss: 0.023735, Accuracy: 99.36%\nEpoch [6/50], Loss: 0.007135, Accuracy: 99.74%\nEpoch [7/50], Loss: 0.051919, Accuracy: 98.46%\nEpoch [8/50], Loss: 0.170477, Accuracy: 97.30%\nEpoch [9/50], Loss: 0.065666, Accuracy: 98.58%\nEpoch [10/50], Loss: 0.033036, Accuracy: 99.36%\nEpoch [11/50], Loss: 0.283197, Accuracy: 96.40%\nEpoch [12/50], Loss: 0.137230, Accuracy: 97.17%\nEpoch [13/50], Loss: 0.112488, Accuracy: 98.33%\nEpoch [14/50], Loss: 0.127059, Accuracy: 97.68%\nEpoch [15/50], Loss: 0.024609, Accuracy: 98.97%\nEpoch [16/50], Loss: 0.002314, Accuracy: 99.87%\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport os\nfrom PIL import Image\nimport torch\nfrom torch.utils.data import Dataset\nimport torchvision.transforms as transforms\n\n# Custom Dataset class for test data (no labels)\nclass TestDataset(Dataset):\n    def __init__(self, csv_file, image_dir, transform=None):\n        \"\"\"\n        Args:\n            csv_file (string): Path to the CSV file with image IDs.\n            image_dir (string): Directory with all the images.\n            transform (callable, optional): Optional transform to be applied on a sample.\n        \"\"\"\n        self.image_df = pd.read_csv(csv_file)\n        self.image_dir = image_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_df)\n\n    def __getitem__(self, idx):\n        img_name = str(self.image_df.iloc[idx, 0])  # Convert the image ID to string\n        try:\n            img_path = os.path.join(self.image_dir, img_name + '.jpg')  # Adjust extension if needed\n            image = Image.open(img_path).convert(\"RGB\")\n        except:\n            img_path = os.path.join(self.image_dir, img_name + '.png')  # Adjust extension if needed\n            image = Image.open(img_path).convert(\"RGB\")\n            \n        if self.transform:\n            image = self.transform(image)\n\n        return image, img_name\n\n# Example usage for test data\ncsv_file = '/kaggle/input/penyisihan-hology-7-data-mining-competition/sample_submission.csv'\n# test_dir = '/kaggle/input/penyisihan-hology-7-data-mining-competition/test/test'\ntest_dir = '/kaggle/input/plis-segmented/test_segmented'\n\ntransform = transforms.Compose([\n    transforms.Resize((128, 128)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Create the test dataset\ntest_dataset = TestDataset(csv_file=csv_file, image_dir=test_dir, transform=transform)\n\n# DataLoader for batching\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T09:43:56.176746Z","iopub.execute_input":"2024-10-27T09:43:56.177147Z","iopub.status.idle":"2024-10-27T09:43:56.196653Z","shell.execute_reply.started":"2024-10-27T09:43:56.177104Z","shell.execute_reply":"2024-10-27T09:43:56.195726Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# model = torch.load('/kaggle/input/warna_332/pytorch/default/1/warna_330.pth')","metadata":{"execution":{"iopub.status.busy":"2024-10-27T09:43:56.197941Z","iopub.execute_input":"2024-10-27T09:43:56.198334Z","iopub.status.idle":"2024-10-27T09:43:56.202586Z","shell.execute_reply.started":"2024-10-27T09:43:56.198290Z","shell.execute_reply":"2024-10-27T09:43:56.201692Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def predict(model, test_loader):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = model.to(device)\n    model.eval()  # Set model to evaluation mode\n\n    predictions = []\n    \n    with torch.no_grad():  # No need to calculate gradients\n        for images, img_ids in test_loader:\n            images = images.to(device)\n\n            # Forward pass\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)  # Get the predicted class\n\n            # Collect results\n            for img_id, pred in zip(img_ids, predicted):\n                predictions.append((img_id, pred.item()))  # Store image ID and prediction\n\n    return predictions\n\ntest_predictions = predict(model, test_loader)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T09:43:56.203679Z","iopub.execute_input":"2024-10-27T09:43:56.204570Z","iopub.status.idle":"2024-10-27T09:43:58.122000Z","shell.execute_reply.started":"2024-10-27T09:43:56.204525Z","shell.execute_reply":"2024-10-27T09:43:58.121095Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import csv\n\ndef save_predictions_to_csv(predictions, output_file):\n    # Save the predictions (image_id, predicted_class) to a CSV file\n    with open(output_file, mode='w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow([\"id\", \"warna\"])  # Header\n        writer.writerows(predictions)\n\n# Example usage to save predictions to a file\noutput_file = '330.csv'\nsave_predictions_to_csv(test_predictions, output_file)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T09:43:58.125244Z","iopub.execute_input":"2024-10-27T09:43:58.125569Z","iopub.status.idle":"2024-10-27T09:43:58.134304Z","shell.execute_reply.started":"2024-10-27T09:43:58.125532Z","shell.execute_reply":"2024-10-27T09:43:58.133375Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}